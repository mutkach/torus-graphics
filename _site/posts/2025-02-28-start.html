<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Torus Blog - LLM surgery for debugging</title>
        <link rel="stylesheet" href="../css/default.css" />
    </head>
    <body>
        <header>
            <div class="logo">
                <a href="../">Torus Blog</a>
            </div>
            <nav>
                <a href="../">Home</a>
                <a href="../about.html">About</a>
                <a href="../contact.html">Contact</a>
                <a href="../archive.html">Archive</a>
            </nav>
        </header>

        <main role="main">
            <h1>LLM surgery for debugging</h1>
            <article>
    <section class="header">
        Posted on February 28, 2025
        
            by mutkach
        
    </section>
    <section>
        <p><em>Problem: You have downloaded and tested a new model from HF or any framework and now you need to run it elsewhere/ship it/deploy it. However the end result seem to be different and sometimes it’s even completely wrong</em></p>
<p>Let’s take for example Llama-3.2-11B-Visual. We’ll pick TensorRT-LLM as our “production” backend.</p>
<p>I use it for simple Visual QA for some screenshots or web snapshots</p>
<p>Butchering the LLM with</p>
<ol type="1">
<li>Register debug outputs</li>
<li>Create debugging wrapper for HF blocks</li>
<li>Write debug outputs to .pt files | Write HF outputs</li>
<li>Compare outputs: plot and/or corrcoef.</li>
<li>Compare outputs of the same network but between layers</li>
<li>Inject HF layer outputs manually</li>
</ol>
    </section>
</article>

        </main>

        <footer>
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>
        </footer>
    </body>
</html>
